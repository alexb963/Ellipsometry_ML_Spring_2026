{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd239b8b-4800-495e-9af3-8fe3d7c8a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3dbd19-7dd6-443c-b03f-cf7c1eafb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lorentz(E, *params):\n",
    "    \"\"\"\n",
    "    Compute the Lorentz oscillator dielectric function.\n",
    "\n",
    "    Parameters:\n",
    "    - E:     array of photon energies (eV)\n",
    "    *params: list of parameter values in order [ A1, Br1, E1, A2, Br2, E2...... An, Brn, En]\n",
    "   \n",
    "    - An:    oscillator amplitude\n",
    "    - Br:    broadening parameter\n",
    "    - En:    resonance energy\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with columns:\n",
    "        • 'Energy (eV)'  \n",
    "        • 'e1' (real dielectric)  \n",
    "        • 'e2' (imaginary dielectric)  \n",
    "        • 'e'  (complex dielectric)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Ensure energies are in an array\n",
    "    E = np.array(E)\n",
    "\n",
    "    # 1.5 Get parameters from params \n",
    "\n",
    "    An = np.array(params[0::3])\n",
    "    Brn = np.array(params[1::3])\n",
    "    En = np.array(params[2::3])\n",
    "\n",
    "    # 2) Compute complex dielectric: ε = ε_inf + (An·Br·En) / (En² − E² − i·Br·E)\n",
    "\n",
    "    dielectric = np.zeros_like(E) # initalize dielectic function to be 0s\n",
    "\n",
    "    for Ai, Bri, Ei in zip(An, Brn, En):\n",
    "    \n",
    "        numerator   = Ai * Bri * Ei\n",
    "        denominator = Ei**2 - E**2 - 1j * Bri * E\n",
    "        dielectric  =  dielectric + numerator / denominator\n",
    "\n",
    "    # 3) Split into real (e1) and imaginary (e2) parts\n",
    "    e1 = dielectric.real\n",
    "    e2 = dielectric.imag\n",
    "\n",
    "    # 4) Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Photon Energy (eV)': E,\n",
    "        'e1':          e1,\n",
    "        'e2':          e2,\n",
    "        'e':           dielectric\n",
    "    })\n",
    "\n",
    "    # 5) Annotate name and source_info for metadata\n",
    "    \"\"\"\n",
    "    Needs to be updated if used in ML\n",
    "    \n",
    "    df.name = f\"A_{An}_Br_{Br}_En_{En}_Einf_{einf}\"\n",
    "    df.attrs[\"source_info\"] = {\n",
    "        \"model\":   \"Lorentz\",\n",
    "        \"An\":      An,\n",
    "        \"Br\":      Br,\n",
    "        \"En\":      En,\n",
    "        \"Einf\":    einf\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    return df\n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83c43e9-04b9-43c3-b60a-b98457d14545",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Drude Function ######################\n",
    "\n",
    "def drude(E, *params):\n",
    "    \"\"\"\n",
    "    Compute Drude-model dielectric function for free carriers.\n",
    "\n",
    "    Parameters:\n",
    "    - E:       array of photon energies (eV)\n",
    "    *params: list of parameter values in order [ rho_1, tau_fs1, rho_2, tau_fs2, ......rho_n, tau_fsn]\n",
    "    \n",
    "    - rho_n:   material resistivity (Ohm·cm)\n",
    "    - tau_fs:  carrier scattering time (fs)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with:\n",
    "        • 'Energy (eV)'  \n",
    "        • 'e1' (real part of ε)  \n",
    "        • 'e2' (imaginary part of ε)  \n",
    "        • 'e'  (complex dielectric function)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Get parameters \n",
    "\n",
    "    rhon = np.array(params[0::2])\n",
    "    taun = np.array(params[1::2])\n",
    "\n",
    "    \n",
    "    # 1.1) Physical constants\n",
    "    hbar     = 6.582119569e-16   # Reduced Planck constant [eV·s]\n",
    "    eps0     = 8.854e-14         # Vacuum permittivity [F/cm]\n",
    "    taun      = taun * 1e-15    # Convert scattering time from fs to s\n",
    "\n",
    "    # 2) Drude numerator & denominator\n",
    "    #    ε(ω) = -ħ² / [ε₀·ρ_n·(τ·E² + i·ħ·E)]\n",
    "\n",
    "    dielectric = np.zeros_like(E) # initalize dielectic function to be 0s\n",
    "\n",
    "    # 3) Compute complex dielectric function\n",
    "    for rhoi, taui in zip(rhon, taun):\n",
    "        \n",
    "        numerator   = -hbar**2\n",
    "        denominator = eps0 * rhoi * (taui * E**2 + 1j * hbar * E)\n",
    "        \n",
    "        dielectric  =  dielectric + numerator / denominator\n",
    "\n",
    "\n",
    "    # 4) Separate real and imaginary parts\n",
    "    e1 = dielectric.real\n",
    "    e2 = dielectric.imag\n",
    "\n",
    "    # 5) Assemble results into a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Photon Energy (eV)': E,\n",
    "        'e1':          e1,\n",
    "        'e2':          e2,\n",
    "        'e':           dielectric\n",
    "    })\n",
    "\n",
    "    # 6) Annotate metadata for traceability\n",
    "\n",
    "    \"\"\"\n",
    "    Needs to be updated if used in ML\n",
    "    \n",
    "    df.name = f\"Drude_rho{rho_n}_tau{tau_fs}\"\n",
    "    df.attrs[\"source_info\"] = {\n",
    "        \"model\":   \"Drude\",\n",
    "        \"rho_n\":   rho_n,\n",
    "        \"tau_fs\":  tau_fs\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7371594-73d2-4186-ae49-d2d616183b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Function that does Sellmeier #######################################\n",
    "\n",
    "def Sellmeier( A_ir, A_uv, E_uv, e_inf, E):\n",
    "    \"\"\"\n",
    "    Compute the real dielectric function using the Sellmeier model.\n",
    "\n",
    "    Parameters:\n",
    "    - A_uv:   UV absorption strE_uvgth coefficiE_uvt\n",
    "    - A_ir:   IR absorption strE_uvgth coefficiE_uvt\n",
    "    - E_uv:     resonance E_uvergy (eV)\n",
    "    - e_inf:  high-frequE_uvcy permittivity\n",
    "    - E:      array of photon E_uvergies (eV)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with:\n",
    "        • 'E_uvergy (eV)'  \n",
    "        • 'e1' (real dielectric)  \n",
    "        • 'e2' (imaginary part, zero)  \n",
    "        • 'e'  (complex dielectric = e1 + 0j)\n",
    "    \"\"\"\n",
    "    # 1) Compute componE_uvts\n",
    "    UV_dielectric = A_uv / (E_uv**2 - E**2)\n",
    "    IR_dielectric = -A_ir / (E**2)\n",
    "    e1 = UV_dielectric + IR_dielectric + e_inf\n",
    "\n",
    "    # 2) Imaginary part is zero for Sellmeier\n",
    "    e2 = np.zeros_like(E)\n",
    "    dielectric = e1 + 0j\n",
    "\n",
    "    # 3) Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Photon Energy (eV)': E,\n",
    "        'e1':          e1,\n",
    "        'e2':          e2,\n",
    "        'e':           dielectric\n",
    "    })\n",
    "\n",
    "    # 4) Add metadata\n",
    "    df.attrs[\"source_info\"] = {\n",
    "        \"model\":  \"Sellmeier\",\n",
    "        \"A_uv\":   A_uv,\n",
    "        \"A_ir\":   A_ir,\n",
    "        \"E_uv\":     E_uv,\n",
    "        \"e_inf\":  e_inf\n",
    "    }\n",
    "    df.name = f\"Sellmeier_Auv_{A_uv}_Air_{A_ir}_E_uv_{E_uv}_Einf_{e_inf}\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe04cde-8c7a-4f6c-8667-3d0f0d4f5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get X axis #####\n",
    "def get_x_axis(df):\n",
    "    if 'Wavelength' in df.columns:\n",
    "        return df['Wavelength (nm)'], 'Wavelength (nm)'\n",
    "    elif 'Energy (eV)' in df.columns:\n",
    "        return df['Energy (eV)'], 'Photon Energy (eV)'\n",
    "    elif 'Photon Energy (eV)' in df.columns:\n",
    "        return df['Photon Energy (eV)'], 'Photon Energy (eV)'\n",
    "    else:\n",
    "        raise ValueError(\"Neither 'Wavelength' nor 'Photon Energy' found in DataFrame.\")\n",
    "\n",
    "### EMA #####\n",
    "def Bruggeman_EMA_Roussel(M1, M2, c, name=False):\n",
    "\n",
    "    \n",
    "    x_data, x_label = get_x_axis(M1)\n",
    "\n",
    "    \n",
    "    N1, N2 = M1['N'].to_numpy(), M2['N'].to_numpy()\n",
    "    p = N1 / N2\n",
    "    b = 0.25 * ((3*c - 1) * ((1/p) - p) + p)\n",
    "    z = b + np.sqrt(b*b + 0.5)\n",
    "    e = z * N1 * N2\n",
    "    e1, e2 = e.real, e.imag\n",
    "    mag = np.sqrt(e1*e1 + e2*e2)\n",
    "    n = np.sqrt((mag + e1)/2)\n",
    "    k = np.sqrt((mag - e1)/2)\n",
    "    df = pd.DataFrame({x_label: x_data, 'e1': e1, 'e2': e2, 'N': n + 1j*k})\n",
    "    if name:\n",
    "        df.name = f\"EMA_{M1.name}_{M2.name}_{c:.2f}\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9d3db1-9515-4401-a6b5-31c4fae6d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sumosscilator(df_list):\n",
    "    \"\"\"\n",
    "    Combine multiple oscillator DataFrames into a single composite dielectric.\n",
    "\n",
    "    Parameters:\n",
    "    - df_list: list of DataFrames, each with:\n",
    "        • 'Energy (eV)'\n",
    "        • 'e1' (real part)\n",
    "        • 'e2' (imaginary part)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing:\n",
    "        • summed 'e1' and 'e2'\n",
    "        • complex dielectric 'e = e1 + 1j·e2'\n",
    "        • preserved 'Energy (eV)' axis\n",
    "        • metadata listing each component's source_info\n",
    "    \"\"\"\n",
    "    # 1) Use the x axis from the first oscillator\n",
    "\n",
    "    x_data, x_label = get_x_axis(df_list[0])\n",
    "    \n",
    "\n",
    "    # 2) Sum real and imaginary contributions across all oscillators\n",
    "    e1_total = sum(df[\"e1\"].values for df in df_list)\n",
    "    e2_total = sum(df[\"e2\"].values for df in df_list)\n",
    "    e_total  = e1_total + 1j * e2_total\n",
    "\n",
    "    # 2.5) Calculate n and k \n",
    "\n",
    "    n, k = calculate_n_k(e1_total, e2_total)\n",
    "    N = n + 1j * k\n",
    "\n",
    "    # 3) Build the composite DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        x_label: x_data,\n",
    "        \"e1\": e1_total,\n",
    "        \"e2\": e2_total,\n",
    "        \"e\":  e_total,\n",
    "        'n': n,\n",
    "        'k': k,\n",
    "        'N': N\n",
    "    })\n",
    "\n",
    "    # 4) Attach metadata listing each component's model info\n",
    "    df.attrs[\"source_info\"] = {\n",
    "        \"model\":      \"Composite\",\n",
    "        \"components\": [\n",
    "            d.attrs.get(\"source_info\", {\"model\": \"Unknown\"})\n",
    "            for d in df_list\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0fc8f-f99a-4290-b9b6-21cbcd35b72d",
   "metadata": {},
   "source": [
    "The next set of functions will all be related to the CPPB + Urbach Tail Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4153d8fd-6689-492d-b36d-55208752c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPPB_WVASE(E, *params, derivative=False ):\n",
    "    \"\"\"\n",
    "    Computes ε2(E) using CPPB oscillators. Uses equations provided in CompleteEASE manual.\n",
    "\n",
    "    Parameters:\n",
    "    - E: array-like, photon energies in eV\n",
    "    - *params: flattened list of parameters [A1, Theta1, Br1, E1, mu1, ... An, Thetan, Brn, En, mun]\n",
    "\n",
    "    A: Amplitude\n",
    "    Theta: Phase angle in degrees\n",
    "    Br: Broadening\n",
    "    E: Resonance Energy \n",
    "    Mu: Dimensionality\n",
    "\n",
    "    Returns:\n",
    "    a pandas dataframe with:\n",
    "    - ε2(E): numpy array of the same shape as E\n",
    "    - ε1(E): numpy array of the same shape as E\n",
    "\n",
    "    The first and second derivatives of ε1 and ε2 will also be provided if derivative = True\n",
    "    \"\"\"\n",
    "\n",
    "    E = np.array(E)\n",
    "    # Step 1: Get Parameters \n",
    "    \n",
    "    A     = np.array(params[0::5]) #  start at 0, every 5th parameter is A\n",
    "    Theta = np.array(params[1::5]) #  start at 1, every 5th parameter is Theta\n",
    "    Br    = np.array(params[2::5]) #  start at 2, every 5th parameter is Br\n",
    "    En    = np.array(params[3::5]) #  start at 3, every 5th parameter is En\n",
    "    mun   = np.array(params[4::5]) #  start at 4, every 5th parameter is mun\n",
    "\n",
    "\n",
    "    # Step 2: Find bandgap (lowest En)\n",
    "    E0 = np.min(En)\n",
    "\n",
    "    # Step 3: Calculate ε2 for E >= E0 (above bandgap)\n",
    "    e2_total = np.zeros_like(E)\n",
    "    e1_total = np.zeros_like(E)\n",
    "\n",
    "    # Fill arrays with 0s for derivatives if needed.\n",
    "    if derivative:\n",
    "\n",
    "        e2_d1 = np.zeros_like(E)\n",
    "        e1_d1 = np.zeros_like(E)\n",
    "    \n",
    "        e2_d2 = np.zeros_like(E)\n",
    "        e1_d2 = np.zeros_like(E)\n",
    "     \n",
    "\n",
    "    for Ai, Ti, Bi, Ei, mui in zip(A, Theta, Br, En, mun):\n",
    "\n",
    "        if mui == 0: \n",
    "            \n",
    "            exp_term =  Ai * np.exp( 1j * Ti * np.pi / 180)\n",
    "            \n",
    "            log_term = np.log( 2 * Ei - 2*E - 1j * Bi)\n",
    "            #print(log_term)\n",
    "            \n",
    "            epsilon = exp_term * log_term\n",
    "            \n",
    "            e1_total +=  epsilon.real\n",
    "            \n",
    "            e2_total +=  epsilon.imag\n",
    "            \n",
    "            if derivative:\n",
    "\n",
    "\n",
    "                numerator_d1 = -1 * exp_term\n",
    "        \n",
    "                denominator_d1 = ( Ei - E - 0.5 * 1j * Bi ) \n",
    "        \n",
    "                epsilon_d1 = (numerator_d1 / denominator_d1)\n",
    "        \n",
    "                e1_d1 +=  epsilon_d1.real\n",
    "                e2_d1 +=  epsilon_d1.imag\n",
    "    \n",
    "               \n",
    "                numerator_d2 = -2 * exp_term\n",
    "        \n",
    "                denominator_d2 = ( Ei - E - 0.5 * 1j * Bi )**2\n",
    "        \n",
    "                epsilon_d1 = (numerator_d1 / denominator_d1)\n",
    "        \n",
    "                e1_d2 +=  epsilon_d2.real\n",
    "                e2_d2 +=  epsilon_d2.imag\n",
    "           \n",
    "\n",
    "        else: \n",
    "        \n",
    "            exp_term = np.exp( 1j * Ti * np.pi / 180)\n",
    "    \n",
    "            numerator = Ai * exp_term * (0.5 * Bi)** mui\n",
    "    \n",
    "            denominator = ( Ei - E - 0.5 * 1j * Bi ) ** mui\n",
    "    \n",
    "            epsilon = (numerator / denominator)\n",
    "    \n",
    "            e1_total +=  epsilon.real\n",
    "            e2_total +=  epsilon.imag\n",
    "\n",
    "\n",
    "            if derivative:\n",
    "    \n",
    "                numerator_d1 = mui * Ai * exp_term * (0.5 * Bi)** mui\n",
    "        \n",
    "                denominator_d1 = ( Ei - E - 0.5 * 1j * Bi ) ** (mui + 1)\n",
    "        \n",
    "                epsilon_d1 = (numerator_d1 / denominator_d1)\n",
    "        \n",
    "                e1_d1 +=  epsilon_d1.real\n",
    "                e2_d1 +=  epsilon_d1.imag\n",
    "    \n",
    "                numerator_d2 = mui * (mui + 1) * Ai * exp_term * (0.5 * Bi)** mui\n",
    "        \n",
    "                denominator_d2 = ( Ei - E - 0.5 * 1j * Bi ) ** (mui + 2)\n",
    "        \n",
    "                epsilon_d2 = (numerator_d2/ denominator_d2)\n",
    "        \n",
    "                e1_d2 +=  epsilon_d2.real\n",
    "                e2_d2 +=  epsilon_d2.imag\n",
    "\n",
    "\n",
    "    if derivative:\n",
    "\n",
    "                     \n",
    "        df = pd.DataFrame({\n",
    "        'Photon Energy (eV)': E,\n",
    "        'e1':  e1_total,\n",
    "        'e2': e2_total,\n",
    "        'e1_d1': e1_d1,\n",
    "        'e2_d1': e2_d1,  \n",
    "        'e1_d2': e1_d2,\n",
    "        'e2_d2': e2_d2, \n",
    "        })\n",
    "\n",
    "    else:\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "        'Energy': E,\n",
    "        'e1':  e1_total,\n",
    "        'e2': e2_total,\n",
    "        })\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def get_CPPB_Urbach( E, *params, derivative=False): \n",
    "\n",
    "    \"\"\"\n",
    "    Computes ε2(E) using CPPB oscillators and an Urbach tail for E < E0.\n",
    "\n",
    "    Parameters:\n",
    "    - E: array-like, photon energies in eV\n",
    "    - *params: flattened list of parameters [A1, Theta1, Br1, E1, mu1, ... An, Thetan, Brn, En, mun, Eu]\n",
    "\n",
    "    A: Amplitude\n",
    "    Theta: Phase angle in degrees\n",
    "    Br: Broadening\n",
    "    E: Resonance Energy \n",
    "    Mu: Dimensionality\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Step 1: Get parameters \n",
    "    E = np.array(E)\n",
    "\n",
    "    Eu = params[-1] # get Eu parameter\n",
    "    param = params[:-1] # remove the Eu value from the others\n",
    "    \n",
    "    A     = np.array(param[0::5]) #  start at 0, every 5th parameter is A\n",
    "    Theta = np.array(param[1::5]) #  start at 1, every 5th parameter is Theta\n",
    "    Br    = np.array(param[2::5]) #  start at 2, every 5th parameter is Br\n",
    "    En    = np.array(param[3::5]) #  start at 3, every 5th parameter is En\n",
    "    mun   = np.array(param[4::5]) #  start at 4, every 5th parameter is mun\n",
    "\n",
    "    # Step 2: Find bandgap and transition Energy\n",
    "    Et = En.min() + 0.5 * Eu \n",
    "    E0 = Et\n",
    "\n",
    "    # Step 3: Calculate e2 above transition energy using the \"CPPB_WVASE\" function.\n",
    "\n",
    "    cp_mask = E >= E0 # define a mask\n",
    "\n",
    "    if derivative:\n",
    "\n",
    "        df = CPPB_WVASE(E, *param, derivative=True) # make sure to input a set of params that does not contain Eu\n",
    "        e2_total = np.zeros_like(E)\n",
    "        e2_d1 = np.zeros_like(E)\n",
    "        e2_d2 = np.zeros_like(E)\n",
    "        e2_total[cp_mask] = df['e2'][cp_mask]\n",
    "        e2_d1[cp_mask] = df['e2_d1'][cp_mask]\n",
    "        e2_d2[cp_mask] = df['e2_d2'][cp_mask]\n",
    "\n",
    "    else: \n",
    "\n",
    "        df = CPPB_WVASE(E, *param, derivative=False)\n",
    "        e2_total = np.zeros_like(E)\n",
    "        e2_total[cp_mask] = df['e2'][cp_mask]\n",
    "\n",
    "    \n",
    "    # Step 4: Urbach tail for E < E0\n",
    "    e2_E0 = 0.0\n",
    "    for Ai, Ti, Bi, Ei, mui in zip(A, Theta, Br, En, mun):\n",
    "        exp_term = np.exp(1j * Ti * np.pi / 180)\n",
    "        z_E0 = Ei - E0 - 0.5j * Bi\n",
    "        e2_E0 +=  ((Ai * exp_term)  * ( 0.5 * Bi /z_E0)** mui).imag\n",
    "\n",
    "    cp_mask_urbach = E < E0\n",
    "    e2_total[cp_mask_urbach] += e2_E0 * np.exp((E[cp_mask_urbach] - E0) / Eu)\n",
    "\n",
    "    # Step 4.5: Calculate derivatives if needed. \n",
    "    if derivative: \n",
    "\n",
    "        e2_d1[cp_mask_urbach] += e2_E0 * (1/ Eu) * np.exp((E[cp_mask_urbach] - E0) / Eu)\n",
    "        e2_d2[cp_mask_urbach] += e2_E0 * (1/ Eu)**2 * np.exp((E[cp_mask_urbach] - E0) / Eu)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "        'Photon Energy (eV)': E,\n",
    "        'e2':  e2_total,\n",
    "        'e2_d1': e2_d1,\n",
    "        'e2_d2': e2_d2,\n",
    "            \n",
    "        })\n",
    "    \n",
    "        return (df)\n",
    "\n",
    "       \n",
    "    else: \n",
    "\n",
    "        df = pd.DataFrame({\n",
    "        'Energy': E,\n",
    "        'e2':  e2_total,\n",
    "            \n",
    "        })\n",
    "    \n",
    "        return (df)\n",
    "\n",
    "\n",
    "\n",
    "################################## KK integration Function ####################################################\n",
    "\n",
    "\n",
    "#Try custom build function\n",
    "\n",
    "def kk_e1_from_e2_ev(energy_ev, e2, E_inf, A_ir, A_uv, Euv ):\n",
    "    \"\"\"\n",
    "    Calculate the real part of the dielectric function ε₁(E) from ε₂(E)\n",
    "    using the Kramers-Kronig relation over photon energy (in eV).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    energy_ev : ndarray\n",
    "        Photon energies in eV (must be > 0 and sorted).\n",
    "    e2 : ndarray\n",
    "        Imaginary part of dielectric function (same length as energy_ev).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    e1 : ndarray\n",
    "        Real part of dielectric function at each energy point.\n",
    "    \"\"\"\n",
    "    energy_ev = np.array(energy_ev)\n",
    "    e2 = np.array(e2)\n",
    "    e1 = np.zeros_like(energy_ev)\n",
    "\n",
    "    for i, E in enumerate(energy_ev):\n",
    "        integrand = np.zeros_like(energy_ev)\n",
    "        for j, Ep in enumerate(energy_ev):\n",
    "            if i == j:\n",
    "                integrand[j] = 0.0  # Exclude singularity at E = Ep\n",
    "            else:\n",
    "                integrand[j] = Ep * e2[j] / (Ep**2 - E**2)\n",
    "        \n",
    "        # Integrate over non-uniform energy axis using trapezoidal rule\n",
    "        e1[i] = (2 / np.pi) * np.trapz(integrand, energy_ev)\n",
    "\n",
    "    # Calculate and add sellmeier \n",
    "    df = Sellmeier(A_ir, A_uv, Euv, E_inf, energy_ev)\n",
    "    e1_temp = df['e1'].to_numpy()\n",
    "\n",
    "    e1 = e1 + e1_temp\n",
    "\n",
    "    return e1\n",
    "\n",
    "\n",
    "################# Calculate n and k when needed ##############################\n",
    "\n",
    "def calculate_n_k(eps1, eps2):\n",
    "    abs_eps = np.sqrt(eps1**2 + eps2**2)\n",
    "    n = np.sqrt((abs_eps + eps1) / 2)\n",
    "    k = np.sqrt((abs_eps - eps1) / 2)\n",
    "    return n, k\n",
    "\n",
    "\n",
    "\n",
    "################ CPPB + Urbach with e1 ########################\n",
    "\n",
    "\n",
    "\n",
    "def get_full_CPPB_Urbach( E, *params):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes ε2(E) using CPPB oscillators and an Urbach tail for E < E0.\n",
    "    Also computes ε1(E) with KK-integration\n",
    "\n",
    "    Parameters:\n",
    "    - E: array-like, photon energies in eV\n",
    "  - *params: flattened list of parameters [A1, Theta1, Br1, E1, mu1, ... An, Thetan, Brn, En, mun] + Eu, Einf,  A_ir, A_uv, E_uv]\n",
    "\n",
    "  \n",
    "    A: Amplitude\n",
    "    Theta: Phase angle in degrees\n",
    "    Br: Broadening\n",
    "    E: Resonance Energy \n",
    "    Mu: Dimensionality\n",
    "\n",
    "    \n",
    "    Eu: Urbach Energy \n",
    "    Einf: Constant additive term used in Sellmeier \n",
    "    A_uv: UV pole amplitude \n",
    "    E_uv: Uv pole energy\n",
    "    A_ir: IR pole amplitude\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - ε2(E): numpy array of the same shape as E\n",
    "    - ε1(E): numpy array of the same shape as E\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Determine the average spacing of the energy spectra \n",
    "\n",
    "    E_length = len(E) # determine lenght of E\n",
    "    E_min = E.min() # min value of E\n",
    "    E_max = E.max() # max value of E\n",
    "\n",
    "    avg_spacing = (E_max - E_min) / E_length\n",
    "\n",
    "    # Step 1.1 expand energy range using this average spacing\n",
    "\n",
    "    E_temp = np.arange(0.001, 7, avg_spacing)\n",
    "\n",
    "\n",
    "    # Step 1.2 get parameters for get_CPPB_Urbach Function and Sellmeier \n",
    "\n",
    "    E_uv = params[-1]\n",
    "    A_uv  = params[-2]\n",
    "    A_ir  = params[-3]\n",
    "    E_inf = params[-4]\n",
    "\n",
    "    CPPB_params = params[:-4]\n",
    "   \n",
    "\n",
    "    # Step 2: Use other CPPB_Urbach model to get e2\n",
    "\n",
    "    df_e2 = get_CPPB_Urbach(E_temp, *CPPB_params)\n",
    "    E2 = df_e2['e2'].to_numpy()\n",
    "\n",
    "    # Step 3: Use KK-integration to get E1\n",
    "    \n",
    "    E1 = kk_e1_from_e2_ev( E_temp , E2, E_inf, A_ir, A_uv, E_uv )\n",
    "\n",
    "    # Step 4: Interpolate E1 \n",
    "\n",
    "    E1_interp = np.interp(E, E_temp, E1)\n",
    "\n",
    "    # Step 4.5: Calculate E2 using the correct photon energy range \n",
    "\n",
    "    df_e2 = get_CPPB_Urbach(E, *CPPB_params)\n",
    "    E2 = df_e2['e2'].to_numpy()\n",
    "\n",
    "\n",
    "    \n",
    "    #Step 5: reorder to match CompleteEASE \n",
    "    eps1 = E1_interp[::-1]\n",
    "    eps2 = E2[::-1]\n",
    "    E = E[::-1]\n",
    "\n",
    "    # Step 5.5 calculate n and k \n",
    "\n",
    "    n, k = calculate_n_k(eps1, eps2)\n",
    "\n",
    "    N = n + 1j * k\n",
    "    \n",
    "    # Step 6: export \n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    'Photon Energy (eV)': E,\n",
    "    'e1': eps1,\n",
    "    'e2': eps2,\n",
    "    'N': N,\n",
    "    'n': n, \n",
    "    'k': k,\n",
    "        \n",
    "    })\n",
    "\n",
    "    df_inverted = df.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return ( df_inverted)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d1f9e7-18e5-48ad-ae43-eac040325cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TL_WVASE( E, *params, derivative = False):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes ε2(E) using Tauc-Loretnz Oscillator\n",
    "\n",
    "    Parameters:\n",
    "    - E: array-like, photon energies in eV\n",
    "    - *params: flattened list of parameters [A1, Eo1, Br1, A2, Eo2, Br2.... An, Eon, Brn, Eg]\n",
    "\n",
    "    A: Amplitude\n",
    "    Eo: resonance energy \n",
    "    Br: Broadening\n",
    "    Eg: Tauc Gap Energy\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Get Parameters \n",
    "\n",
    "    # Exclude Eg from parameters \n",
    "    Eg = params[-1]\n",
    "    param = params[:-1]\n",
    "\n",
    "    # Get other params\n",
    "\n",
    "    A     = np.array(param[0::3], dtype=np.complex128) #  start at 0, every 5th parameter is A\n",
    "    Eo    = np.array(param[1::3], dtype=np.complex128) #  start at 3, every 5th parameter is En\n",
    "    Br    = np.array(param[2::3], dtype=np.complex128) #  start at 2, every 5th parameter is Br\n",
    "\n",
    "    # Calculate E2 above Eg\n",
    "\n",
    "    E2_mask = E >= Eg # define a mask\n",
    "\n",
    "    e2_TL = np.zeros_like(E)\n",
    "    for Ai, Eoi, Bri in zip(A, Eo, Br):\n",
    "\n",
    "        numerator = (Ai * Eoi * Bri * (E - Eg)**2).real\n",
    "        denominator = ((E**2 - Eoi**2)**2 + (Bri**2 * E**2)).real\n",
    "        e2_TL[E2_mask] = e2_TL[E2_mask] + ( ( numerator[E2_mask] / denominator[E2_mask]) * (1 / E[E2_mask]) )\n",
    "\n",
    "\n",
    "    if derivative: \n",
    "    \n",
    "        e2_TL_d1 = np.zeros_like(E)\n",
    "        for Ai, Eoi, Bri in zip(A, Eo, Br):\n",
    "\n",
    "            factors = (Ai * Eoi * Bri * (E - Eg)).real\n",
    "            numerator_d1 = (Eg * (Eoi**4 - 6 * Eoi**2 * E**2 + 3 * Bri**2 * E**2 + 5* E**4) + Eoi**4 * E + 2 * Eoi**2 * E**3 - E**3 * (Bri**2 + 3 * E**2)).real\n",
    "            denominator_d1 = (E**2 * ( Eoi**4 - 2 * Eoi**2 * E**2 + Bri**2 * E**2 + E**4 )**2).real\n",
    "\n",
    "            e2_TL_d1[E2_mask] = e2_TL_d1[E2_mask] +  factors[E2_mask]  * (numerator_d1[E2_mask] / denominator_d1[E2_mask])\n",
    "            \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "        e2_TL_d2 = np.zeros_like(E)\n",
    "        for Ai, Eoi, Bri in zip(A, Eo, Br):\n",
    "\n",
    "            factors = (Ai * Eoi * Bri).real\n",
    "            \n",
    "            term1 =   ( (2 * ( 4*E * (E**2 - Eoi**2) + 2 * Bri**2 * E)**2) / ( (E**2 - Eoi**2)**2 + Bri**2 * E**2)**3 ).real\n",
    "\n",
    "            term2 =  ( (4 * (E**2 - Eoi**2) + 2 * Bri**2 + 8 * E**2 ) / ( (E**2 - Eoi**2)**2 + Bri**2 * E**2)**2 ).real\n",
    "\n",
    "            term3 =  (( (E - Eg)**2 * ( term1 - term2) ) / E).real\n",
    "\n",
    "            term4 = ( ( 2 * ( 2*((E - Eg) / E) - ((E - Eg)**2 / E**2)) * (4*E*(E**2 - Eoi**2) + 2*Bri**2 * E) ) / ( (E**2 - Eoi**2)**2 + Bri**2 * E**2)**2 ).real\n",
    "\n",
    "            term5 = ((2 * (E-Eg)**2 / E**3) - (4 * (E - Eg) / E**2) + 2/E).real\n",
    "\n",
    "            term6 = ((E**2 - Eoi**2)**2 + Bri**2 * E**2).real\n",
    "\n",
    "            term7 = term5 / term6\n",
    "\n",
    "            e2_TL_d2[E2_mask] = e2_TL_d2[E2_mask] +  factors * ( term3[E2_mask] - term4[E2_mask] + term7[E2_mask])\n",
    "\n",
    "            \n",
    "        \n",
    "   \n",
    "\n",
    "    if derivative: \n",
    "\n",
    "        df = pd.DataFrame({\n",
    "        'Energy': E,\n",
    "        'e2':  e2_TL.real,\n",
    "        'e2_d1': e2_TL_d1.real,\n",
    "        'e2_d2': e2_TL_d2.real\n",
    "            \n",
    "        })\n",
    "\n",
    "    else: \n",
    "         \n",
    "        df = pd.DataFrame({\n",
    "        'Energy': E,\n",
    "        'e2':  e2_TL.real,\n",
    "            \n",
    "        })\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1632f72b-8f98-41d2-b9d0-fd77399afe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now a CPPB function with an Urbach Tail Background will be made\n",
    "\n",
    "\n",
    "def get_CPPB_Urbach_TL_Background( E, *params, derivative = False): \n",
    "\n",
    "    \"\"\"\n",
    "    Computes ε2(E) using CPPB oscillators and an Urbach tail for E < E0.\n",
    "    This function also has a Tauc-Loretnz background oscillator\n",
    "\n",
    "    Parameters:\n",
    "    - E: array-like, photon energies in eV\n",
    "    - *params: flattened list of parameters [A1, Theta1, Br1, E1, mu1, ... An, Thetan, Brn, En, mun, TL_Amp, TL_Eo, TL_Br, Eu]\n",
    "\n",
    "    A: Amplitude\n",
    "    Theta: Phase angle in degrees\n",
    "    Br: Broadening\n",
    "    E: Resonance Energy \n",
    "    Mu: Dimensionality\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Step 1: Get parameters \n",
    "    E = np.array(E)\n",
    "\n",
    "    Eu = params[-1] # get Eu parameter\n",
    "    param = params[:-4] # remove the Eu value and TL values from the others\n",
    "    # Get TL Values\n",
    "    TL_Eo = params[-3]\n",
    "    TL_Br = params[-2]\n",
    "    TL_Amp = params[-4]\n",
    "    \n",
    "    A     = np.array(param[0::5], dtype=np.complex128) #  start at 0, every 5th parameter is A\n",
    "    Theta = np.array(param[1::5], dtype=np.complex128) #  start at 1, every 5th parameter is Theta\n",
    "    Br    = np.array(param[2::5], dtype=np.complex128) #  start at 2, every 5th parameter is Br\n",
    "    En    = np.array(param[3::5], dtype=np.complex128) #  start at 3, every 5th parameter is En\n",
    "    mun   = np.array(param[4::5], dtype=np.complex128) #  start at 4, every 5th parameter is mun\n",
    "\n",
    "    # Step 2: Find bandgap and transition Energy\n",
    "    Et = En.min() + 0.5 * Eu \n",
    "    E0 = Et\n",
    "    TL_Eg = E0 # Tauc Gap\n",
    "\n",
    "    # Step 3: Calculate e2 above transition energy using the \"CPPB_WVASE\" function and Tauc-Loretnz\n",
    "\n",
    "    cp_mask = E >= E0 # define a mask\n",
    "\n",
    "    TL_params = [TL_Amp, TL_Eo, TL_Br, TL_Eg]\n",
    "\n",
    "    if derivative:\n",
    "    \n",
    "        df1 = CPPB_WVASE(E, *param, derivative=True)\n",
    "        df2 = get_TL_WVASE( E, *TL_params, derivative=True)\n",
    "\n",
    "    else: \n",
    "\n",
    "        df1 = CPPB_WVASE(E, *param, derivative=False)\n",
    "        df2 = get_TL_WVASE( E, *TL_params, derivative=False)\n",
    "        \n",
    "    \n",
    "    e2_total = np.zeros_like(E)\n",
    "    e2_total[cp_mask] = df1['e2'][cp_mask] + df2['e2'][cp_mask]\n",
    "\n",
    "    if derivative:\n",
    "\n",
    "        # Calculate derivative above Et \n",
    "        e2_d1 = np.zeros_like(E)\n",
    "        e2_d2 = np.zeros_like(E)\n",
    "\n",
    "        e2_d1[cp_mask] = df1['e2_d1'][cp_mask] + df2['e2_d1'][cp_mask]\n",
    "        e2_d2[cp_mask] = df1['e2_d2'][cp_mask] + df2['e2_d2'][cp_mask]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Step 4: Urbach tail for E < E0\n",
    "    e2_E0 = 0.0\n",
    "    for Ai, Ti, Bi, Ei, mui in zip(A, Theta, Br, En, mun):\n",
    "        exp_term = np.exp(1j * Ti * np.pi / 180)\n",
    "        z_E0 = Ei - E0 - 0.5j * Bi\n",
    "        e2_E0 +=  ((Ai * exp_term)  * ( 0.5 * Bi /z_E0)** mui).imag\n",
    "    \n",
    "    cp_mask_urbach = E < E0\n",
    "    e2_total[cp_mask_urbach] += e2_E0 * (np.exp((E[cp_mask_urbach] - E0) / Eu)).real\n",
    "\n",
    "\n",
    "    if derivative: \n",
    "    \n",
    "        #print(Eu)\n",
    "        e2_d1[cp_mask_urbach] += e2_E0 * ((1/ Eu) * np.exp((E[cp_mask_urbach] - E0) / Eu)).real\n",
    "        e2_d2[cp_mask_urbach] += e2_E0 * ((1/ Eu)**2 * np.exp((E[cp_mask_urbach] - E0) / Eu)).real\n",
    "\n",
    "    #Step 5: Return E2 and Energy as a df\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "        'Photon Energy (eV)': E,\n",
    "        'e2':  e2_total,\n",
    "        'e2_d1': e2_d1,\n",
    "        'e2_d2': e2_d2,\n",
    "            \n",
    "        })\n",
    "\n",
    "        return (df)\n",
    "\n",
    "    else: \n",
    "            \n",
    "        df = pd.DataFrame({\n",
    "        'Energy': E,\n",
    "        'e2':  e2_total,\n",
    "            \n",
    "        })\n",
    "    \n",
    "        return (df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0af0469-e829-4b60-b47d-48823df0ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_full_CPPB_Urbach_TL_Background( E, *params):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes ε2(E) using CPPB oscillators and an Urbach tail for E < E0.\n",
    "    Also computes ε1(E) with KK-integration\n",
    "\n",
    "    Parameters:\n",
    "    - E: array-like, photon energies in eV\n",
    "  - *params: flattened list of parameters [A1, Theta1, Br1, E1, mu1, ... An, Thetan, Brn, En, mun] + TL_Amp, TL_Eo, TL_Br, Eu Einf,  A_ir, A_uv, E_uv]\n",
    "\n",
    "  \n",
    "    A: Amplitude\n",
    "    Theta: Phase angle in degrees\n",
    "    Br: Broadening\n",
    "    E: Resonance Energy \n",
    "    Mu: Dimensionality\n",
    "\n",
    "    \n",
    "    Eu: Urbach Energy \n",
    "    Einf: Constant additive term used in Sellmeier \n",
    "    A_uv: UV pole amplitude \n",
    "    E_uv: Uv pole energy\n",
    "    A_ir: IR pole amplitude\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - ε2(E): numpy array of the same shape as E\n",
    "    - ε1(E): numpy array of the same shape as E\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Determine the average spacing of the energy spectra \n",
    "\n",
    "    E_length = len(E) # determine lenght of E\n",
    "    E_min = E.min() # min value of E\n",
    "    E_max = E.max() # max value of E\n",
    "\n",
    "    avg_spacing = (E_max - E_min) / E_length\n",
    "\n",
    "    # Step 1.1 expand energy range using this average spacing\n",
    "\n",
    "    E_temp = np.arange(0.001, 7, avg_spacing)\n",
    "\n",
    "\n",
    "    # Step 1.2 get parameters for get_CPPB_Urbach, Tauc_Lorentz, and Sellmeier \n",
    "\n",
    "    # Sellmeier\n",
    "    E_uv = params[-1]\n",
    "    A_uv  = params[-2]\n",
    "    A_ir  = params[-3]\n",
    "    E_inf = params[-4]\n",
    "    \n",
    "\n",
    "    CPPB_params = params[:-4]\n",
    "   \n",
    "\n",
    "    # Step 2: Use CPPB_Urbach + TL model to get e2\n",
    "\n",
    "    df_e2 = get_CPPB_Urbach_TL_Background(E_temp, *CPPB_params)\n",
    "    E2 = df_e2['e2'].to_numpy()\n",
    "\n",
    "    # Step 3: Use KK-integration to get E1\n",
    "    \n",
    "    E1 = kk_e1_from_e2_ev( E_temp , E2, E_inf, A_ir, A_uv, E_uv )\n",
    "\n",
    "    # Step 4: Interpolate E1 \n",
    "\n",
    "    E1_interp = np.interp(E, E_temp, E1)\n",
    "\n",
    "    # Step 4.5: Calculate E2 using the correct photon energy range \n",
    "\n",
    "    df_e2 = get_CPPB_Urbach_TL_Background(E, *CPPB_params)\n",
    "    E2 = df_e2['e2'].to_numpy()\n",
    "\n",
    "\n",
    "    \n",
    "    #Step 5: reorder to match CompleteEASE \n",
    "    eps1 = E1_interp[::-1]\n",
    "    eps2 = E2[::-1]\n",
    "    E = E[::-1]\n",
    "\n",
    "    # Step 5.5 calculate n and k \n",
    "\n",
    "    n, k = calculate_n_k(eps1, eps2)\n",
    "\n",
    "    N = n + 1j * k\n",
    "    \n",
    "    # Step 6: export \n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    'Photon Energy (eV)': E,\n",
    "    'e1': eps1,\n",
    "    'e2': eps2,\n",
    "    'N': N,\n",
    "    'n': n, \n",
    "    'k': k,\n",
    "        \n",
    "    })\n",
    "\n",
    "    df_inverted = df.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return ( df_inverted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0c949-8e86-4baf-b75d-01c9e13a8473",
   "metadata": {},
   "source": [
    "The next set of function are related to generating the SE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd8307-ae5d-49eb-83f1-521bad232295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Snells_Law(Structure, AOI):\n",
    "    Nmat = np.stack([df[\"N\"].to_numpy() for df in Structure])\n",
    "    L, P = Nmat.shape\n",
    "    angles = np.zeros((L,P), dtype=complex)\n",
    "    angles[0] = np.radians(AOI)\n",
    "    for i in range(1, L):\n",
    "        angles[i] = np.arcsin((Nmat[i-1]/Nmat[i]) * np.sin(angles[i-1]))\n",
    "    return angles\n",
    "\n",
    "\n",
    "def fresnel_coefficients(N, angles):\n",
    "    n1, n2 = N[:-1], N[1:]\n",
    "    t1, t2 = angles[:-1], angles[1:]\n",
    "    cos1, cos2 = np.cos(t1), np.cos(t2)\n",
    "    ds = n1*cos1 + n2*cos2\n",
    "    dp = n2*cos1 + n1*cos2\n",
    "    rs = (n1*cos1 - n2*cos2)/ds\n",
    "    ts = (2*n1*cos1)/ds\n",
    "    rp = (n2*cos1 - n1*cos2)/dp\n",
    "    tp = (2*n1*cos1)/dp\n",
    "    return rs, rp, ts, tp\n",
    "\n",
    "def Scattering_Matrix(N, angles, d, lam, r, t):\n",
    "    L, P = N.shape\n",
    "    d = d[:,None]; lam=lam[None,:]\n",
    "    E = (2*np.pi/lam)*N[1:-1]*d*np.cos(angles[1:-1])\n",
    "    prop = np.zeros((L-2,P,2,2), dtype=complex)\n",
    "    prop[:,:,0,0] = np.exp(-1j*E)\n",
    "    prop[:,:,1,1] = np.exp( 1j*E)\n",
    "    interf = np.zeros((L-1,P,2,2), dtype=complex)\n",
    "    interf[:,:,0,0] = 1/t; interf[:,:,0,1] = r/t\n",
    "    interf[:,:,1,0] = r/t; interf[:,:,1,1] = 1/t\n",
    "    S = interf[0]\n",
    "    for i in range(1, L-1):\n",
    "        S = S @ prop[i-1] @ interf[i]\n",
    "    return S\n",
    "\n",
    "\n",
    "def SE_Sim(Structure, AOI, d, write_data=False, NCS=True):\n",
    "    wv = Structure[0]['Wavelength (nm)'].to_numpy()\n",
    "    Nmat = np.stack([df[\"N\"].to_numpy() for df in Structure])\n",
    "    angles = Snells_Law(Structure, AOI)\n",
    "    rs, rp, ts, tp = fresnel_coefficients(Nmat, angles)\n",
    "    Ss = Scattering_Matrix(Nmat, angles, d, wv, rs, ts)\n",
    "    Sp = Scattering_Matrix(Nmat, angles, d, wv, rp, tp)\n",
    "    Rp = Sp[:,1,0]/Sp[:,0,0]\n",
    "    Rs = Ss[:,1,0]/Ss[:,0,0]\n",
    "    rho = np.conj(Rp/Rs)\n",
    "    psi = np.arctan(np.abs(rho)).real\n",
    "    delta = np.unwrap(np.angle(rho))\n",
    "    Nval = np.cos(2*psi).real\n",
    "    C = (np.sin(2*psi)*np.cos(delta)).real\n",
    "    S = (np.sin(2*psi)*np.sin(delta)).real\n",
    "    if NCS:\n",
    "        return pd.DataFrame({'Wavelength (nm)': wv, 'N': Nval, 'C': C, 'S': S})\n",
    "    else:\n",
    "        return pd.DataFrame({\n",
    "            'Wavelength (nm)': wv,\n",
    "            'Psi':   psi*180/np.pi,\n",
    "            'Delta': delta*180/np.pi\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e342f8-5306-4e9d-848e-fefb34775832",
   "metadata": {},
   "source": [
    "Next function calculates Sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315ab2d9-42d2-4fb4-9c04-229ce6cbe44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sigma_weighted(\n",
    "    N_model, N_exp,\n",
    "    C_model, C_exp,\n",
    "    S_model, S_exp,\n",
    "    n, m,\n",
    "    var=0.001\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the weighted sigma fit‐metric:\n",
    "    \n",
    "      σ = sqrt(  1/(3n − m)  ∑[ (N_i^m − N_i^e)²/var\n",
    "                              + (C_i^m − C_i^e)²/var\n",
    "                              + (S_i^m − S_i^e)²/var ]\n",
    "            )\n",
    "    \n",
    "    where `var` is the denominator (≈0.001) under each squared term.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N_model, C_model, S_model : array‐like\n",
    "        Modeled spectra values.\n",
    "    N_exp, C_exp, S_exp : array‐like\n",
    "        Experimental spectra values.\n",
    "    n : int\n",
    "        Number of data points (length of each spectrum).\n",
    "    m : int\n",
    "        Number of fit parameters.\n",
    "    var : float, optional\n",
    "        Denominator under each squared residual (default 0.001).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sigma : float\n",
    "        The weighted fit‐quality metric.\n",
    "    \"\"\"\n",
    "    # ensure numpy arrays\n",
    "    N_model = np.asarray(N_model)\n",
    "    N_exp   = np.asarray(N_exp)\n",
    "    C_model = np.asarray(C_model)\n",
    "    C_exp   = np.asarray(C_exp)\n",
    "    S_model = np.asarray(S_model)\n",
    "    S_exp   = np.asarray(S_exp)\n",
    "    \n",
    "    # element‐wise squared differences, divided by var\n",
    "    resid_N = ( (N_model - N_exp)  /var   )**2 \n",
    "    resid_C = ( (C_model - C_exp)  /var   )**2\n",
    "    resid_S = ( (S_model - S_exp)  /var  )**2\n",
    "    \n",
    "    # sum over all points & channels\n",
    "    total = np.sum(resid_N + resid_C + resid_S)\n",
    "    \n",
    "    # divide by degrees of freedom and take sqrt\n",
    "    sigma = np.sqrt(total / (3*n - m))\n",
    "    return sigma\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb646f8-8584-4541-907f-187c9182d17b",
   "metadata": {},
   "source": [
    "The next set of functions will focus on improving logistics and visualization for curvfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "629ac1e4-0548-437a-9a72-cb38e21c0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define a function that can group the outputs. \n",
    "\n",
    "def group_by_number_sorted(params, fixed_mask, perr):\n",
    "    \"\"\"\n",
    "    Group params into dictionary format with error tracking.\n",
    "    Input params are assumed to already be sorted by number:\n",
    "    [A1, T1, Br1, En1, Mu1, A2, T2, ..., MuN, Einf, Eu, Delta]\n",
    "\n",
    "    Returns:\n",
    "        dict of {label+number or special: (value, error or None)}\n",
    "    \"\"\"\n",
    "    labels = [\"A\", \"T\", \"Br\", \"En\", \"Mu\"]\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    total_params = len(params)\n",
    "    Eu_index = total_params - 5\n",
    "    einf_index = total_params - 4\n",
    "    Air_index = total_params - 3\n",
    "    Auv_index = total_params - 2\n",
    "    Euv_index = total_params - 1\n",
    "\n",
    "    num_grouped = total_params - 5\n",
    "    group_size = num_grouped // num_labels\n",
    "\n",
    "    # Step 1: Build map of param_index -> error for free parameters\n",
    "    free_indices = [i for i, is_fixed in enumerate(fixed_mask) if not is_fixed]\n",
    "    if len(free_indices) != len(perr):\n",
    "        raise ValueError(\"Mismatch between number of free params and errors!\")\n",
    "\n",
    "    index_to_error = {idx: err for idx, err in zip(free_indices, perr)}\n",
    "\n",
    "    # Step 2: Build dictionary directly (since already number-sorted)\n",
    "    ordered_result = {}\n",
    "\n",
    "    for i in range(group_size):  # i = number index\n",
    "        for label_index, label in enumerate(labels):\n",
    "            param_index = i * num_labels + label_index\n",
    "            key = f\"{label}{i+1}\"\n",
    "            value = params[param_index]\n",
    "            error = index_to_error.get(param_index, None)\n",
    "            ordered_result[key] = (value, error)\n",
    "\n",
    "    # Step 3: Handle Einf, Eu, Delta\n",
    "    for key, idx in [(\"Eu\", Eu_index), (\"Einf\", einf_index), (\"Air\", Air_index), (\"Auv\", Auv_index), (\"Euv\", Euv_index)]:\n",
    "        val = params[idx]\n",
    "        err = index_to_error.get(idx, None)\n",
    "        ordered_result[key] = (val, err)\n",
    "\n",
    "    return ordered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb0d4f8-7d2b-4ebc-9359-9117e1421814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get derivatives when provided e2 from numerical inversion or other tabulated forms.\n",
    "\n",
    "def e2_derivatives(E, e2):\n",
    "\n",
    "    \"\"\" Inputs e2 spectra, outputs the derivatives \"\"\"\n",
    "\n",
    "    x = np.array(E)\n",
    "    y = np.array(e2)\n",
    "    \n",
    "    dy_dx = np.gradient(y,x)\n",
    "    dy2_dx2 = np.gradient(dy_dx,x)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'Energy': x,\n",
    "    'e2':  y,\n",
    "    'e2_d1': dy_dx,\n",
    "    'e2_d2': dy2_dx2,\n",
    "        \n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c59f10-1621-4355-8f1e-7b8fb69c822e",
   "metadata": {},
   "source": [
    "The next section is functions related to fitting SE data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c5cb2a-b639-4869-83d5-87648fdeb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Unpack / Pack functions\n",
    "# -------------------------------\n",
    "\n",
    "def unpack_params(flat_params, schema):\n",
    "    \"\"\"Convert flat param dict into structured layer objects.\"\"\"\n",
    "    structured_layers = []\n",
    "    \n",
    "    for layer in schema:\n",
    "        lname = layer[\"name\"]\n",
    "        ltype = layer[\"type\"]\n",
    "        structured = {\"name\": lname, \"type\": ltype}\n",
    "        \n",
    "        # --- tabulated ---\n",
    "        if ltype == \"tabulated\":\n",
    "            if \"thickness\" in layer:\n",
    "                structured[\"thickness\"] = flat_params.get(f\"{lname}_Thickness\", None)\n",
    "            structured[\"data\"] = layer[\"data\"]\n",
    "        \n",
    "        # --- EMA ---\n",
    "        elif ltype == \"ema\":\n",
    "            structured[\"thickness\"] = flat_params.get(f\"{lname}_Thickness\", None)\n",
    "            structured[\"fraction\"] = flat_params.get(f\"{lname}_Fraction\", None)\n",
    "            structured[\"ema\"] = layer[\"ema\"]\n",
    "        \n",
    "        # --- Oscillator ---\n",
    "        elif ltype == \"oscillator\":\n",
    "            structured[\"thickness\"] = flat_params.get(f\"{lname}_Thickness\", None)\n",
    "            structured[\"oscillators\"] = []\n",
    "            \n",
    "            for osc in layer[\"oscillators\"]:\n",
    "                otype = osc[\"type\"]\n",
    "\n",
    "                # --- CPPB (flexible number of oscillators) ---\n",
    "                if otype == \"CPPB\":\n",
    "                    cppb_params = {}\n",
    "                    i = 1\n",
    "                    # detect however many oscillators exist\n",
    "                    while f\"{lname}_CPPB_A{i}\" in flat_params:\n",
    "                        labels = [f\"A{i}\", f\"T{i}\", f\"Br{i}\", f\"En{i}\", f\"Mu{i}\"]\n",
    "                        values = [flat_params[f\"{lname}_CPPB_{lab}\"] for lab in labels]\n",
    "                        cppb_params.update(dict(zip(labels, values)))\n",
    "                        i += 1\n",
    "                    # tail parameters\n",
    "                    for lab in [ \"TL_Amp\", \"TL_Eo\", \"TL_Br\", \"Eu\", \"Einf\", \"Air\", \"Auv\", \"En\"]:\n",
    "                        if f\"{lname}_CPPB_{lab}\" in flat_params:\n",
    "                            cppb_params[lab] = flat_params[f\"{lname}_CPPB_{lab}\"]\n",
    "                    structured[\"oscillators\"].append({\"type\": \"CPPB\", \"params\": cppb_params})\n",
    "\n",
    "                # --- Lorentz ---\n",
    "                elif otype == \"Lorentz\":\n",
    "                    lorentz_list = []\n",
    "                    i = 1\n",
    "                    while f\"{lname}_Lorentz_A{i}\" in flat_params:\n",
    "                        labels = [f\"A{i}\", f\"Br{i}\", f\"E{i}\"]\n",
    "                        values = [flat_params[f\"{lname}_Lorentz_{lab}\"] for lab in labels]\n",
    "                        lorentz_list.append(dict(zip(labels, values)))\n",
    "                        i += 1\n",
    "                    structured[\"oscillators\"].append({\"type\": \"Lorentz\", \"params\": lorentz_list})\n",
    "\n",
    "                # --- Sellmeier ---\n",
    "                elif otype == \"Sellmeier\":\n",
    "                    labels = [\"Air\",\"Auv\",\"Euv\",\"Einf\"]\n",
    "                    values = [flat_params[f\"{lname}_Sellmeier_{lab}\"] for lab in labels]\n",
    "                    structured[\"oscillators\"].append({\"type\": \"Sellmeier\", \"params\": dict(zip(labels, values))})\n",
    "\n",
    "                # --- Drude ---\n",
    "                elif otype == \"Drude\":\n",
    "                    labels = [\"rho1\",\"tau1\"]\n",
    "                    values = [flat_params[f\"{lname}_Drude_{lab}\"] for lab in labels]\n",
    "                    structured[\"oscillators\"].append({\"type\": \"Drude\", \"params\": dict(zip(labels, values))})\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown layer type: {ltype}\")\n",
    "        \n",
    "        structured_layers.append(structured)\n",
    "    \n",
    "    return structured_layers\n",
    "\n",
    "\n",
    "def pack_params(structured_layers, schema):\n",
    "    \"\"\"Convert structured layers back into flat param dict.\"\"\"\n",
    "    flat = {}\n",
    "    \n",
    "    for layer in structured_layers:\n",
    "        lname = layer[\"name\"]\n",
    "        ltype = layer[\"type\"]\n",
    "        \n",
    "        if ltype == \"tabulated\":\n",
    "            if \"thickness\" in layer:\n",
    "                flat[f\"{lname}_Thickness\"] = layer.get(\"thickness\")\n",
    "        \n",
    "        elif ltype == \"ema\":\n",
    "            flat[f\"{lname}_Thickness\"] = layer.get(\"thickness\")\n",
    "            flat[f\"{lname}_Fraction\"] = layer.get(\"fraction\")\n",
    "        \n",
    "        elif ltype == \"oscillator\":\n",
    "            flat[f\"{lname}_Thickness\"] = layer.get(\"thickness\")\n",
    "            \n",
    "            for osc in layer[\"oscillators\"]:\n",
    "                otype = osc[\"type\"]\n",
    "\n",
    "                # --- CPPB (flexible) ---\n",
    "                if otype == \"CPPB\":\n",
    "                    for k, v in osc[\"params\"].items():\n",
    "                        flat[f\"{lname}_CPPB_{k}\"] = v\n",
    "                \n",
    "                # --- Lorentz ---\n",
    "                elif otype == \"Lorentz\":\n",
    "                    for lor in osc[\"params\"]:\n",
    "                        for k, v in lor.items():\n",
    "                            flat[f\"{lname}_Lorentz_{k}\"] = v\n",
    "                \n",
    "                # --- Sellmeier ---\n",
    "                elif otype == \"Sellmeier\":\n",
    "                    for k, v in osc[\"params\"].items():\n",
    "                        flat[f\"{lname}_Sellmeier_{k}\"] = v\n",
    "                \n",
    "                # --- Drude ---\n",
    "                elif otype == \"Drude\":\n",
    "                    for k, v in osc[\"params\"].items():\n",
    "                        flat[f\"{lname}_Drude_{k}\"] = v\n",
    "    \n",
    "    return flat\n",
    "\n",
    "\n",
    "# --- Dict → Array (for curve_fit) ---\n",
    "def dict_to_array(param_dict, schema):\n",
    "    flat_dict = pack_params(unpack_params(param_dict, schema), schema)\n",
    "    return list(flat_dict.values())\n",
    "\n",
    "\n",
    "# --- Array → Dict (after curve_fit updates values) ---\n",
    "def array_to_dict(param_array, schema, template_dict):\n",
    "    flat_dict = pack_params(unpack_params(template_dict, schema), schema)\n",
    "    keys = list(flat_dict.keys())\n",
    "    return dict(zip(keys, param_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb0baa6-ee55-4f8f-940f-efd8726fa89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SE_Data_Gen(layers, E):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        layers - structured layers (from unpack_params)\n",
    "        E - energy grid (numpy array)\n",
    "\n",
    "    Output:\n",
    "        structure - dielectric functions per layer\n",
    "        thicknesses - list of thicknesses\n",
    "    \"\"\"\n",
    "\n",
    "    num_layers = len(layers)\n",
    "    thicknesses = []\n",
    "    structure = [None] * num_layers\n",
    "\n",
    "    #### ----------------- PASS 1: Oscillator + Tabulated layers ----------------- ####\n",
    "    for i, layer in enumerate(layers):\n",
    "        lname, ltype = layer[\"name\"], layer[\"type\"]\n",
    "\n",
    "        # Thickness (may be None for substrate, etc.)\n",
    "        thick = layer.get(\"thickness\", None)\n",
    "        thicknesses.append(thick)\n",
    "\n",
    "        if ltype == \"oscillator\":\n",
    "            eps_contributions = []\n",
    "\n",
    "            # --- Collect all parameters by oscillator type ---\n",
    "            drude_params = []\n",
    "            lorentz_params = []\n",
    "            sellmeier_params = []\n",
    "            cppb_params = []\n",
    "\n",
    "            # flatten parameters for each type\n",
    "            drude_params = [\n",
    "                val for osc in layer[\"oscillators\"] if osc[\"type\"] == \"Drude\"\n",
    "                for val in osc[\"params\"].values()\n",
    "            ]\n",
    "\n",
    "            lorentz_params = [\n",
    "                val for osc in layer[\"oscillators\"] if osc[\"type\"] == \"Lorentz\"\n",
    "                for lor in osc[\"params\"]  # list of dicts\n",
    "                for val in lor.values()\n",
    "            ]\n",
    "\n",
    "            sellmeier_params = [\n",
    "                val for osc in layer[\"oscillators\"] if osc[\"type\"] == \"Sellmeier\"\n",
    "                for val in osc[\"params\"].values()\n",
    "            ]\n",
    "\n",
    "            cppb_params = [\n",
    "                val for osc in layer[\"oscillators\"] if osc[\"type\"] == \"CPPB\"\n",
    "                for val in osc[\"params\"].values()\n",
    "            ]\n",
    "\n",
    "            # --- Call each oscillator function ONCE per type ---\n",
    "            if drude_params:\n",
    "                eps_contributions.append(drude(E, *drude_params))\n",
    "            if lorentz_params:\n",
    "                eps_contributions.append(Lorentz(E, *lorentz_params))\n",
    "            if sellmeier_params:\n",
    "                eps_contributions.append(Sellmeier(*sellmeier_params, E))\n",
    "            if cppb_params:\n",
    "                eps_contributions.append(get_full_CPPB_Urbach_TL_Background(E, *cppb_params))\n",
    "                \n",
    "\n",
    "            #print(eps_contributions[0].equals(Bulk))\n",
    "            #print(lname)\n",
    "            if len(eps_contributions) == 1: \n",
    "                eps_total = eps_contributions[0]\n",
    "            else:\n",
    "                eps_total = sumosscilator(eps_contributions)\n",
    "            \n",
    "            #print(eps_total.equals(Bulk))\n",
    "            structure[i] = eps_total\n",
    "\n",
    "        elif ltype == \"tabulated\":\n",
    "            structure[i] = layer[\"data\"]  # TODO: interpolate if needed\n",
    "\n",
    "        elif ltype == \"ema\":\n",
    "            # Placeholder — fill in Pass 2\n",
    "            structure[i] = None\n",
    "\n",
    "    #### ----------------- PASS 2: EMA layers ----------------- ####\n",
    "    for i, layer in enumerate(layers):\n",
    "        if layer[\"type\"] == \"ema\":\n",
    "    \n",
    "            comp1_idx = layer[\"ema\"][\"components\"][0][\"layer\"]\n",
    "            comp2_idx = layer[\"ema\"][\"components\"][1][\"layer\"]\n",
    "            Mat1 = structure[comp1_idx]\n",
    "            Mat2 = structure[comp2_idx]\n",
    "            f2 = layer[\"fraction\"]\n",
    "\n",
    "            EMA = Bruggeman_EMA_Roussel(Mat1, Mat2, f2)\n",
    "            structure[i] = EMA\n",
    "\n",
    "    # Drop Nones from thickness list (substrates, etc.)\n",
    "    thicknesses = np.array([t for t in thicknesses if t is not None])\n",
    "\n",
    "    # Step 4: Simulate ellipsometric spectra\n",
    "    SE_Data = SE_Sim(structure, 64.93, thicknesses, write_data=False, NCS=True)\n",
    "\n",
    "    # Step 5: return ellipsometric spectra\n",
    "    return SE_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82293c7e-befd-47e3-bb2b-79fae0b2897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "\n",
    "def fit_SE_with_fixed_params(E, exp_data, schema, param_dict, fixed_mask, bounds=None):\n",
    "    \"\"\"\n",
    "    Fit ellipsometric spectra using SE_Data_Gen with fixed/free parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    E : array\n",
    "        Energy grid.\n",
    "    exp_data : DataFrame\n",
    "        Experimental spectra with at least [\"Psi\", \"Delta\"] columns.\n",
    "    schema : dict\n",
    "        Schema used to unpack/pack parameters.\n",
    "    param_dict : dict\n",
    "        Flat dictionary of initial guesses for parameters (packed form).\n",
    "    fixed_mask : list of bool\n",
    "        Same length/order as param_dict.values(). True = fixed, False = free.\n",
    "    bounds : (list, list), optional\n",
    "        Bounds for all params (full space). Will be reduced to free params.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict with keys:\n",
    "        \"fitted_params\" - free params fitted\n",
    "        \"full_params\"   - all params after filling back fixed\n",
    "        \"covariance\"    - covariance from curve_fit\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten initial guesses\n",
    "    all_keys = list(param_dict.keys())\n",
    "    all_params = np.array(list(param_dict.values()), dtype=float)\n",
    "\n",
    "    fixed_mask = np.array(fixed_mask, dtype=bool)\n",
    "    free_mask = ~fixed_mask\n",
    "\n",
    "    m = len(free_mask)\n",
    "    n = len(E)\n",
    "\n",
    "    free_init = all_params[free_mask]\n",
    "\n",
    "    def full_params(free_vals):\n",
    "        \"\"\"Reconstruct full param vector from free subset.\"\"\"\n",
    "        full = np.array(all_params, copy=True)\n",
    "        full[free_mask] = free_vals\n",
    "        return full\n",
    "\n",
    "    def wrapped_model_for_curvefit(E, *free_vals):\n",
    "        \"\"\"Called by curve_fit — must return 1D residuals.\"\"\"\n",
    "        # rebuild flat dict from free params\n",
    "        full = full_params(free_vals)\n",
    "        flat_dict = dict(zip(all_keys, full))\n",
    "\n",
    "        # convert to structured layers\n",
    "        layers = unpack_params(flat_dict, schema)\n",
    "\n",
    "        # generate simulated SE spectra\n",
    "        sim = SE_Data_Gen(layers, E)  # expected DataFrame\n",
    "\n",
    "        # compute residuals\n",
    "                 \n",
    "        res_N = (sim['N'].to_numpy() - exp_data['N'].to_numpy()) / (3 * n - m)\n",
    "        res_C = (sim['C'].to_numpy() - exp_data['C'].to_numpy()) / (3 * n - m)\n",
    "        res_S = (sim['S'].to_numpy() - exp_data['S'].to_numpy()) / (3 * n - m)\n",
    "        \n",
    "        residuals = np.concatenate([res_N, res_C, res_S])\n",
    "\n",
    "        print(\"Params:\", free_vals)\n",
    "        print(\"Residual norm:\", np.linalg.norm(residuals))\n",
    "        \n",
    "        return residuals\n",
    "\n",
    "    # Prepare bounds for free params only\n",
    "    if bounds is not None:\n",
    "        lower_full, upper_full = bounds\n",
    "        lower_free = np.array(lower_full)[free_mask]\n",
    "        upper_free = np.array(upper_full)[free_mask]\n",
    "        bounds_free = (lower_free, upper_free)\n",
    "    else:\n",
    "        bounds_free = (-np.inf, np.inf)\n",
    "\n",
    "    # Dummy ydata: curve_fit compares model output to this\n",
    "    ydata_dummy = np.zeros_like(\n",
    "        wrapped_model_for_curvefit(E, *free_init)\n",
    "    )\n",
    "\n",
    "    # Call curve_fit\n",
    "    popt, pcov = curve_fit(\n",
    "        wrapped_model_for_curvefit,\n",
    "        E,\n",
    "        ydata_dummy,\n",
    "        p0=free_init,\n",
    "        bounds=bounds_free\n",
    "    )\n",
    "\n",
    "    final_params = full_params(popt)\n",
    "    final_dict = dict(zip(all_keys, final_params))\n",
    "\n",
    "    return {\n",
    "        \"fitted_params\": popt,\n",
    "        \"full_params\": final_params,\n",
    "        \"full_dict\": final_dict,\n",
    "        \"covariance\": pcov\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24e53f5-69df-4a50-a7f5-7372a69cdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_fit_results_with_dict(full_dict, popt, perr, fixed_mask, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Format fitted results using full_dict labels + fit mask.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    full_dict : dict\n",
    "        Dictionary of all parameters after fit (from fit_SE_with_fixed_params).\n",
    "    popt : array\n",
    "        Optimized values for free params (from curve_fit).\n",
    "    perr : array\n",
    "        1σ errors for free params (same order as popt).\n",
    "    fixed_mask : list of bool\n",
    "        True = fixed param, False = free param. Must match dict order.\n",
    "    confidence : float\n",
    "        Confidence level (e.g., 0.95 for ~2σ errors).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Keys = param labels, values = \"value ± error\" or \"value (fixed)\".\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    zval = norm.ppf(0.5 + confidence/2)\n",
    "\n",
    "    all_keys = list(full_dict.keys())\n",
    "    results = {}\n",
    "\n",
    "    idx_free = 0\n",
    "    for i, key in enumerate(all_keys):\n",
    "        val = full_dict[key]\n",
    "\n",
    "        if fixed_mask[i]:\n",
    "            # Fixed parameter\n",
    "            results[key] = f\"{val:.4f} (fixed)\"\n",
    "        else:\n",
    "            # Free parameter → assign error\n",
    "            err = perr[idx_free] * zval\n",
    "            results[key] = f\"{val:.4f} ± {err:.4f}\"\n",
    "            idx_free += 1\n",
    "\n",
    "    # sanity check\n",
    "    assert idx_free == len(popt), f\"Used {idx_free}, expected {len(popt)} free params\"\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def pretty_print_fit_results(results):\n",
    "    \"\"\"\n",
    "    Group flat results dict into layers/models and pretty-print.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        { \"param_label\": \"value ± error\" } from format_fit_results_with_dict.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nested : dict\n",
    "        Nested structure {layer: {model: {param: value_str}}}\n",
    "    text : str\n",
    "        Human-readable block of results.\n",
    "    \"\"\"\n",
    "    nested = {}\n",
    "\n",
    "    for key, val in results.items():\n",
    "        parts = key.split(\"_\")\n",
    "\n",
    "        # Case 1: layer only (Thickness, Fraction, etc.)\n",
    "        if len(parts) == 2:\n",
    "            layer, param = parts\n",
    "            nested.setdefault(layer, {})[param] = val\n",
    "\n",
    "        # Case 2: layer + model + param (e.g., HRT1_Lorentz_A1)\n",
    "        elif len(parts) == 3:\n",
    "            layer, model, param = parts\n",
    "            nested.setdefault(layer, {}).setdefault(model, {})[param] = val\n",
    "\n",
    "        # Case 3: layer + submodel + subsubmodel + param\n",
    "        # (for more complex schemas like CST-Bulk_CPPB_A1)\n",
    "        else:\n",
    "            layer = parts[0]\n",
    "            model = \"_\".join(parts[1:-1])  # everything except last\n",
    "            param = parts[-1]\n",
    "            nested.setdefault(layer, {}).setdefault(model, {})[param] = val\n",
    "\n",
    "    # --- make human-readable text ---\n",
    "    lines = []\n",
    "    for layer, models in nested.items():\n",
    "        lines.append(f\"\\n=== {layer} ===\")\n",
    "        for key, val in models.items():\n",
    "            if isinstance(val, dict):\n",
    "                lines.append(f\"  [{key}]\")\n",
    "                for pname, pval in val.items():\n",
    "                    lines.append(f\"    {pname}: {pval}\")\n",
    "            else:\n",
    "                # direct param under layer\n",
    "                lines.append(f\"  {key}: {val}\")\n",
    "\n",
    "    #text = \"\\n\".join(lines)\n",
    "    return nested #text\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "def format_fit_results_table(full_dict, popt, perr, fixed_mask, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Format fitted results into a DataFrame (easy to print or save as CSV).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    full_dict : dict\n",
    "        Dictionary of all parameters after fit (from fit_SE_with_fixed_params).\n",
    "    popt : array\n",
    "        Optimized values for free params (from curve_fit).\n",
    "    perr : array\n",
    "        1σ errors for free params (same order as popt).\n",
    "    fixed_mask : list of bool\n",
    "        True = fixed param, False = free param. Must match dict order.\n",
    "    confidence : float\n",
    "        Confidence level (e.g., 0.95 for ~2σ errors).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        Columns: [Parameter, Value, Error, Status]\n",
    "    \"\"\"\n",
    "    zval = norm.ppf(0.5 + confidence/2)\n",
    "\n",
    "    all_keys = list(full_dict.keys())\n",
    "    rows = []\n",
    "\n",
    "    idx_free = 0\n",
    "    for i, key in enumerate(all_keys):\n",
    "        val = full_dict[key]\n",
    "\n",
    "        if fixed_mask[i]:\n",
    "            rows.append({\n",
    "                \"Parameter\": key,\n",
    "                \"Value\": val,\n",
    "                \"Error\": None,\n",
    "                \"Status\": \"Fixed\"\n",
    "            })\n",
    "        else:\n",
    "            err = perr[idx_free] * zval\n",
    "            rows.append({\n",
    "                \"Parameter\": key,\n",
    "                \"Value\": val,\n",
    "                \"Error\": err,\n",
    "                \"Status\": \"Fitted\"\n",
    "            })\n",
    "            idx_free += 1\n",
    "\n",
    "    assert idx_free == len(popt), f\"Used {idx_free}, expected {len(popt)} free params\"\n",
    "\n",
    "    results_df = pd.DataFrame(rows)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b3866-20db-4136-9522-0bfb26fda492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
